{"name":"vargplvm","tagline":"Variational Bayesian GP-LVM model in MATLAB.","body":"Bayesian GP-LVM model\r\n=====================\r\n\r\nThis page describes examples of how to use the variational approximation to the Bayesian GP-LVM model.\r\n\r\n\r\nRelease Information\r\n-------------------\r\n\r\n**Current release is 0.2**.\r\n\r\nAs well as downloading the VARGPLVM software you need to obtain the toolboxes specified below. **These can be downloaded using the *same* password you get from registering for the VARGPLVM software.**\r\n\r\n|-----------------------------------------------|-------------|\r\n| **Toolbox**                                   | **Version** |\r\n| [NETLAB](/netlab/downloadFiles/vrs3p3)        | 3.3         |\r\n| [PRIOR](/prior/downloadFiles/vrs0p22)         | 0.22        |\r\n| [OPTIMI](/optimi/downloadFiles/vrs0p132)      | 0.132       |\r\n| [DATASETS](/datasets/downloadFiles/vrs0p1371) | 0.1371      |\r\n| [MLTOOLS](/mltools/downloadFiles/vrs0p138)    | 0.138       |\r\n| [KERN](/kern/downloadFiles/vrs0p227)          | 0.227       |\r\n| [NDLUTIL](/ndlutil/downloadFiles/vrs0p162)    | 0.162       |\r\n| [MOCAP](/mocap/downloadFiles/vrs0p136)        | 0.136       |\r\n| [GP](/gp/downloadFiles/vrs0p137)              | 0.137       |\r\n| [NOISE](/noise/downloadFiles/vrs0p141)        | 0.141       |\r\n\r\nThe released software now includes dynamical models.\r\n\r\n#### Version 0.14\r\n\r\nThis release includes improved numerical stability on the gradient and bound computations which finds better solutions under the optimizer. Derived and implemented by Andreas Damianou and Michalis Titsias.\r\n\r\n#### Version 0.1\r\n\r\nThis release is for the AISTATS 2010 submission.\r\n\r\nExamples\r\n--------\r\n\r\n### Oil Data\r\n\r\nThe 'oil data' is commonly used as a bench mark for visualisation algorithms. For more details on the data see [this page](http://www.ncrg.aston.ac.uk/GTM/3PhaseData.html). In all of the following examples 50 inducing points were used.\r\n\r\n#### Standard dataset\r\n\r\nThe script `demOilVargplvm1.m` runs the Bayesian GP-LVM Model on this dataset, giving the results shown on the left of the figure that follows. The visualization was achieved by keeping the most dominant latent dimensions (2 and 3) which have the largest inverse lengthscale value. Dimension 2 is plotted on the *y*-axis and 3 and on the *x*-axis. The script `demOilVargplvm2.m` is similar but there are missing outputs from test points; the model attempts to reconstruct these missing outputs. The result is shown on the right of the figure.\r\n![](demOilVargplvm1.png)![](demOilVargplvm2.png)\r\n *Left*: Bayesian GP-LVM on the oil data without missing outputs. The phases of flow are shown as green circles, blue crosses and red plusses. *Right*: Similar but in this case 50% of the outputs are missing and the model attempts to reconstruct them.\r\n\r\n#### 100 Inducing Points\r\n\r\nThe script `demOil100Vargplvm1.m` runs the Bayesian GP-LVM Model on the Oil Data with only 100 points in the active set, giving the result on the figure below.\r\n![](demOil100Vargplvm1.png)\r\n Bayesian GP-LVM on the oil data using 100 inducing points.\r\n\r\n### Loop Closure in Robotics\r\n\r\nIn on-going work with Dieter Fox and Brian Ferris at the University of Washington we are interested in loop closure for robotic navigation, included as an example is a data set of a robot completing a loop while reading wireless access point signal strengths. The script `demRobotWirelessVargplvm1.m` runs the Bayesian GP-LVM Model on this dataset in order to produce a neat track and close the loop, as can be seen on the figure shown below.\r\n\r\n![](demRobotWirelessVargplvm1.png)\r\n Use of the Bayesian GP-LVM Model to obtain loop closure in a robot navigation example.\r\n\r\n### Frey Faces Data\r\n\r\nIn this dataset, we try to exploit the ability of the model to reconstruct partially observed test data. Therefore, when the model is trained only half of the image pixels are assumed to be observed. After training on 1000 images, each partially observed test image was processed separately and the missing pixels were predicted as shown on the figures below. The code to obtain the following figures was based on the `demBrendanVargplvm3.m` script.\r\n\r\n![](demBrendanTestImag1_3.png)![](demBrendanTestImag2_3.png)![](demBrendanTestImag4_3.png)![](demBrendanTestImag127_3.png)![](demBrendanTestImag11_3.png)![](demBrendanTestImag24_3.png)![](demBrendanTestImag51_3.png)![](demBrendanTestImag62_3.png)\r\n\r\n![](demBrendanTestImag1WithMissing_3.png)![](demBrendanTestImag2WithMissing_3.png)![](demBrendanTestImag4WithMissing_3.png)![](demBrendanTestImag127WithMissing_3.png)![](demBrendanTestImag11WithMissing_3.png)![](demBrendanTestImag24WithMissing_3.png)![](demBrendanTestImag51WithMissing_3.png)![](demBrendanTestImag62WithMissing_3.png)\r\n\r\n![](demBrendanTestImag1Reconst_3.png)![](demBrendanTestImag2Reconst_3.png)![](demBrendanTestImag4Reconst_3.png)![](demBrendanTestImag127Reconst_3.png)![](demBrendanTestImag11Reconst_3.png)![](demBrendanTestImag24Reconst_3.png)![](demBrendanTestImag51Reconst_3.png)![](demBrendanTestImag62Reconst_3.png)\r\n\r\nExamples of reconstruction of partially observed test images in Frey faces by applying the Bayesian GP-LVM. Each column corresponds to a test image. In every column, the top panel shows the true test image, the middle panel the partially observed image (where missing pixels are shown in black) and the bottom image is the reconstructed image.\r\n\r\n### Dynamical Systems Modelling\r\n\r\nThe Bayesian GPLVM model has been extended with dynamics in a fully Bayesian framework, where a temporal prior is placed on the latent space and the latent points are integrated out. This makes the model suitable for robust modelling of dynamical systems, such as motion capture data or video sequences. Given that the model is generative, the method can also be used to produce novel sequences. The script `demosDynamics.m` reproduces the corresponding experiments. The first diagram below demonstrates the ability of the method to reconstruct partially observed frames taken from a video sequence. The second diagram shows an image which is generated without giving partial information, apart from a time interval for inter- or extrapolation. The video used for that experiment expressed strong periodicity, which allowed the model to be trained on 60 frames and then produce a novel video sequence for any given time interval (in the particular experiment for times 61 to 100). The complete videos generated for these experiments can be found [here](http://staffwww.dcs.shef.ac.uk/people/A.Damianou/varFiles/paper/supplementary/).\r\n\r\n![](missaGpdsPredFrame17.png)\r\n\r\nReconstructing a partially observed frame.\r\n\r\n![](dogGeneration_frame14.png)\r\n\r\nOne of the frames that belong to a video sequence which is generated by the model.\r\n\r\n\r\nPage updated on Tue Nov 22 00:39:27 2011\r\n","google":"UA-62968536-1","note":"Don't delete this file! It's used internally to help with page regeneration."}